import os
import re
import numpy as np
import pandas as pd
import streamlit as st

from sentence_transformers import SentenceTransformer
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer

# ============================
# Streamlit ê¸°ë³¸ ì„¤ì •
# ============================
st.set_page_config(page_title="ì˜ì–‘ì œ-ì•½ë¬¼ êµ°ì§‘ ìœ ì‚¬ë„ ì•±", layout="wide")
st.title("ğŸ’Š ì˜ì–‘ì œ â†’ ì•½ë¬¼ êµ°ì§‘ ìœ ì‚¬ë„ íƒìƒ‰ê¸°")

st.markdown("""
ì—…ë¡œë“œëœ ì•½ë¬¼ ìƒí˜¸ì‘ìš©(db_drug_interactions.csv) ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•½ë¬¼ êµ°ì§‘ì„ ë§Œë“¤ê³ ,  
ì˜ì–‘ì œ ì…ë ¥ ì‹œ ì–´ë–¤ ì•½ë¬¼ êµ°ì§‘ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ì§€ ê³„ì‚°í•´ì¤ë‹ˆë‹¤.
""")


# ============================
# ë°ì´í„° ë¡œë“œ
# ============================
DATA_PATH = "db_drug_interactions.csv"  # ë°˜ë“œì‹œ ì €ì¥ì†Œì— í¬í•¨í•´ì•¼ í•¨
NUM_CLUSTERS = 40
TOP_KEYWORDS = 20

@st.cache_data
def load_raw_data():
    if not os.path.exists(DATA_PATH):
        st.error(f"âŒ '{DATA_PATH}' íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì €ì¥ì†Œì— í¬í•¨ì‹œí‚¤ì„¸ìš”.")
        st.stop()
    df = pd.read_csv(DATA_PATH)
    
    required = {"Drug 1", "Drug 2", "Interaction Description"}
    if not required.issubset(df.columns):
        st.error("âŒ í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: Drug 1, Drug 2, Interaction Description")
        st.stop()
    return df


# ============================
# ì „ì²˜ë¦¬ í•¨ìˆ˜
# ============================
def clean_text(t: str) -> str:
    if pd.isna(t):
        return ""
    t = str(t).lower()
    t = re.sub(r"[^a-zA-Z0-9ê°€-í£\s]", " ", t)
    t = re.sub(r"\s+", " ", t)
    return t.strip()


@st.cache_data
def build_drug_corpus(df):
    df["drug1"] = df["Drug 1"].map(clean_text)
    df["drug2"] = df["Drug 2"].map(clean_text)
    df["desc"]  = df["Interaction Description"].map(clean_text)

    drug_texts = {}

    for _, row in df.iterrows():
        d1, d2, desc = row["drug1"], row["drug2"], row["desc"]

        if d1:
            drug_texts.setdefault(d1, []).append(desc)
        if d2:
            drug_texts.setdefault(d2, []).append(desc)

    drug_list, drug_corpus = [], []
    for drug, texts in drug_texts.items():
        drug_list.append(drug)
        drug_corpus.append(" ".join(texts))

    return drug_list, drug_corpus


# ============================
# ì„ë² ë”© ëª¨ë¸ ë¡œë”©
# ============================
@st.cache_resource
def load_model():
    MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    return SentenceTransformer(MODEL)


# ============================
# ì•½ë¬¼ êµ°ì§‘ ë§Œë“¤ê¸°
# ============================
@st.cache_resource
def build_clusters(drug_list, drug_corpus):
    model = load_model()

    # 1. ì„ë² ë”©
    drug_embs = model.encode(drug_corpus, normalize_embeddings=True)

    # 2. KMeans í´ëŸ¬ìŠ¤í„°ë§
    kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=42, n_init=10)
    cluster_ids = kmeans.fit_predict(drug_embs)

    # 3. êµ°ì§‘ë³„ í…ìŠ¤íŠ¸ ëª¨ìœ¼ê¸°
    cluster_texts = []
    for c in range(NUM_CLUSTERS):
        texts = [drug_corpus[i] for i in range(len(drug_list)) if cluster_ids[i] == c]
        merged = " ".join(texts) if texts else "no data"
        cluster_texts.append(merged)

    # 4. TF-IDF í‚¤ì›Œë“œ ì¶”ì¶œ
    tfidf = TfidfVectorizer(max_features=1000, stop_words="english")
    X = tfidf.fit_transform(cluster_texts)
    terms = tfidf.get_feature_names_out()

    cluster_keywords = []
    for i in range(NUM_CLUSTERS):
        row = X[i].toarray()[0]
        idx = row.argsort()[::-1][:TOP_KEYWORDS]
        keywords = ", ".join([terms[j] for j in idx])
        cluster_keywords.append(keywords)

    cluster_terms_df = pd.DataFrame({
        "cluster_id": list(range(NUM_CLUSTERS)),
        "top_terms": cluster_keywords
    })

    # 5. êµ°ì§‘ í…ìŠ¤íŠ¸ ì„ë² ë”©
    cluster_embs = model.encode(cluster_keywords, normalize_embeddings=True)

    return cluster_terms_df, cluster_embs


# ============================
# ì˜ˆì¸¡ í•¨ìˆ˜
# ============================
def predict_cluster(name, cluster_terms_df, cluster_embs, topn=5):
    model = load_model()
    q = str(name).strip()

    if not q:
        return pd.DataFrame()

    q_emb = model.encode([q], normalize_embeddings=True)[0]
    sims = cluster_embs @ q_emb

    order = np.argsort(-sims)[:topn]

    return pd.DataFrame({
        "cluster_id": cluster_terms_df["cluster_id"].iloc[order].tolist(),
        "similarity": sims[order],
        "top_terms": cluster_terms_df["top_terms"].iloc[order].tolist()
    })


# ============================
# ë©”ì¸ UI
# ============================
df = load_raw_data()
drug_list, drug_corpus = build_drug_corpus(df)
cluster_terms_df, cluster_embs = build_clusters(drug_list, drug_corpus)

st.success("ë°ì´í„° ë¡œë”© & ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")

with st.sidebar:
    st.header("âš™ï¸ ì˜µì…˜")
    user_input = st.text_input("ì˜ì–‘ì œ / ì„±ë¶„ ì´ë¦„ ì…ë ¥", "í™ì‚¼")
    topn = st.slider("Top-N êµ°ì§‘", 3, 15, 5)
    run = st.button("ìœ ì‚¬ë„ ê³„ì‚°í•˜ê¸°")

st.markdown("---")

if run:
    result = predict_cluster(user_input, cluster_terms_df, cluster_embs, topn=topn)

    st.subheader(f"ğŸ” '{user_input}'ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì•½ë¬¼ êµ°ì§‘ Top-{topn}")
    st.dataframe(result)

    st.bar_chart(result.set_index("cluster_id")["similarity"])
else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì˜ì–‘ì œë¥¼ ì…ë ¥í•˜ê³  'ìœ ì‚¬ë„ ê³„ì‚°í•˜ê¸°' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
